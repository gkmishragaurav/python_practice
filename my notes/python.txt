Note - Python key can not be a dictionary. only a fixed object can be a key for a dictionary
run a cmd on another machine in python - use pexpect. for same machine use subprocess.

------------------------------------------------------------------------------------------------------
List cheat sheet:
list.extend(L)
Extend the list by appending all the items in the given list; equivalent to a[len(a):] = L.

list.insert(i, x)
Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x).

list.pop([i])
Remove the item at the given position in the list,


----------------------------------------------------------------------------------------------------

Difference between Compiled and Interpreted Language:

Compiled Language:
	Compiled languages are converted directly into machine code that the processor can execute. 
	It is one where the program, once compiled, is expressed in the instructions of the target machine - machine language; 
	this machine code is undecipherable by humans. Types of compiled language – C, C++, C#, CLEO, COBOL, etc.
	In this language, compiled programs run faster than interpreted programs.
	This language delivers better performance.
	It also gives the developer more control over hardware aspects, like memory management and CPU usage.
	Compiled languages need a “build” step – they need to be manually compiled first. You need to “rebuild” the program every time you need to make a change.

Interpreted Language:
	Interpreters run through a program line by line and execute each command.
	It is one where the instructions are not directly executed by the target machine, 
	but instead read and executed by some other program. Interpreted language ranges – JavaScript, Perl, Python, BASIC, etc.
	While in this language, interpreted programs can be modified while the program is running.
	This languages delivers relatively slower performance.

Okay… but what does that actually mean?
	Imagine you have a hummus recipe that you want to make, but it's written in ancient Greek. 
	There are two ways you, a non-ancient-Greek speaker, could follow its directions.

	The first is if someone had already translated it into English for you. 
	You (and anyone else who can speak English) could read the English version of the recipe and make hummus. 
	Think of this translated recipe as the compiled version.

	The second way is if you have a friend who knows ancient Greek. 
	When you're ready to make hummus, your friend sits next to you and translates 
	the recipe into English as you go, line by line. 
	In this case, your friend is the interpreter for the interpreted version of the recipe.

-----------------------------------------------------------------------------

Internal working of Python:

	Python doesn’t convert its code into machine code, something that hardware can understand.
	It actually converts it into something called byte code, which is stored with a .pyc or .pyo format.
	So within python, compilation happens, but it’s just not into a machine language.
	It is into byte code and this byte code can’t be understood by CPU.
	This bytecode is a low-level set of instructions that can be executed by an interpreter. 
	So we need actually an interpreter called the python virtual machine. 
	The python virtual machine executes the byte codes.

The Python interpreter performs following tasks to execute a Python program :

	Step 1: The interpreter reads a python code or instruction. 
			Then it verifies that the instruction is well formatted, i.e. it checks the syntax of each line.
			If it encounters any error, it immediately halts the translation and shows an error message.
	
	Step 2: If there is no error, i.e. if the python instruction or code is well formatted then the interpreter translates it into its equivalent form in intermediate language called “Byte code”.
			Thus, after successful execution of Python script or code, it is completely translated into Byte code.
	
	Step 3: Byte code is sent to the Python Virtual Machine(PVM).
			Here again the byte code is executed on PVM.
			If an error occurs during this execution then the execution is halted with an error message.
			
Why Interpreted?
	One popular advantage of interpreted languages is that they are platform-independent. 
	As long as the Python bytecode and the Virtual Machine have the same version, Python bytecode can be executed on any platform (Windows, MacOS, etc).
			
What is __pycache__ ?
Many times in your personal project or on GitHub, you might have seen a folder named __pycache__ being created automatically.
As you can see, the filename is the same as the one outside __pycache__ folder. 
The .pyc extension tells us that the file contains bytecode for preprocess.py. 
The names cpython denotes the type of interpreter. CPython means that the interpreter was implemented in C language. 
Similarly, JPython is a Python interpreter implemented in Java.

But why is the folder created in the first place? Well, it slightly increases the speed of the Python program. 
Unless you change your Python code, recompilation to bytecode is avoided, thereby saving time.

--------------------------------------------------------------------------------------------------------------

copy in Python (Deep Copy and Shallow Copy)

In Python, Assignment statements do not copy objects, they create bindings between a target and an object. When we use = operator user thinks that this creates a new object; 
well, it doesn’t. It only creates a new variable that shares the reference of the original object. Sometimes a user wants to work with mutable objects, in order to do 
that user looks for a way to create “real copies” or “clones” of these objects. Or, sometimes a user wants copies that user can modify without automatically modifying 
the original at the same time, in order to do that we create copies of objects.

A copy is sometimes needed so one can change one copy without changing the other. In Python, there are two ways to create copies :

    Deep copy
    Shallow copy

# importing copy module 
import copy 
  
# initializing list 1  
li1 = [1, 2, [3,5], 4] 

# using copy for shallow copy   
li2 = copy.copy(li1)  

# using deepcopy for deepcopy   
li3 = copy.deepcopy(li1)  

----------------------------------------------------------------------------------------
GIL:
The Python Global Interpreter Lock or GIL, in simple words, is a mutex (or a lock) that allows only one thread to hold the control of the Python interpreter.

>>> import sys
>>> a = []
>>> b = a
>>> sys.getrefcount(a)
3

In the above example, the reference count for the empty list object [] was 3. The list object was referenced by a, b and the argument passed to sys.getrefcount().

This means that only one thread can be in a state of execution at any point in time. The impact of the GIL isn’t visible to developers who execute single-threaded programs, 
but it can be a performance bottleneck in CPU-bound and multi-threaded code.

Q. What problem did the GIL solve for Python?

Python uses reference counting for memory management. It means that objects created in Python have a reference count variable that keeps track of the number of references 
that point to the object. When this count reaches zero, the memory occupied by the object is released.

The problem was that this reference count variable needed protection from race conditions where two threads increase or decrease its value simultaneously. If this happens, 
it can cause either leaked memory that is never released or, even worse, incorrectly release the memory while a reference to that object still exists. This can can cause 
crashes or other “weird” bugs in your Python programs.

The GIL is a single lock on the interpreter itself which adds a rule that execution of any Python bytecode requires acquiring the interpreter lock. This prevents deadlocks 
(as there is only one lock) and doesn’t introduce much performance overhead. But it effectively makes any CPU-bound Python program single-threaded.

Q. How to deal with Python’s GIL

If the GIL is causing you problems, here a few approaches you can try:

Multi-processing vs multi-threading: The most popular way is to use a multi-processing approach where you use multiple processes instead of threads. Each Python process 
gets its own Python interpreter and memory space so the GIL won’t be a problem. Python has a multiprocessing module which lets us create processes easily like this:

multi threading in python:

1. MT programming is ideal for programming tasks that are asynchronous in nature, require multiple concurrent activities, and where the processing of each activity may 
be nondeterministic, i.e., random and unpredictable.

----------------------------------------------------------------------------------------------------------

Python and OS:

a. python sys module
os module
os.system(): Allows us to execute a shell command
os.listdir(path): Returns a list with the contents of the directory passed as an argument
os.walk(path): Navigates all the directories in the provided path directory, and returns three values: the path directory, the names for the sub directories, and a list 
of filenames in the current directory path.

b. The platform.system() method informs us of the running operating system. Depending on the return value, we can see the ping command is different in Windows and Linux. 
Windows OS uses ping –n 1 to send one packet of the ICMP ECHO request, whereas Linux or another OS uses ping –c 1.

import os
import platform
operating_system = platform.system()
print operating_system
if (operating_system == "Windows"):
    ping_command = "ping -n 1 127.0.0.1"
elif (operating_system == "Linux"):
    ping_command = "ping -c 1 127.0.0.1"
else :
    ping_command = "ping -c 1 127.0.0.1"
print ping_command

c. subprocess module

d. Working with the filesystem in Python:
understand os.walk
os.path.isfile("./main.py")
os.path.exists("./not_exists.py")
os.makedirs('my_dir')
open a file
read a file
write a file

e. Open file with contaxt manager.

https://www.geeksforgeeks.org/context-manager-in-python/

There are multiple ways to create files in Python, but the cleanest way to do this is by using the with keyword, in this case we are using the Context Manager Approach.
Initially, Python provided the open statement to open files. When we are using the open statement, Python delegates into the developer the responsibility to close the file when it's no longer need to use it. This practice lead to errors since developers sometimes forgot to close it. Since Python 2.5, developers can use the with statement to handle this situation safely. The with statement automatically closes the file even if an exception is raised. In this way, we have the advantage: the file is closed automatically and we don’t need to call the close() method.
>>> with open("somefile.txt", "r") as file:
>>> for line in file:
>>> print line

--------------------------------------------------------------------------------------------------------------

http://hplgit.github.io/primer.html/doc/pub/class/class-bootstrap.html
Object oriented python: 

1. Composition is the act of collecting together several objects to compose a new one. Composition is usually a good choice when one object is part of another object.

2. Polymorphism is the ability to treat a class differently depending on which subclass is implemented

3. The one difference between methods and normal functions is that all methods have one required argument. This argument is conventionally named self; I've never seen a 
programmer use any other name for this variable (convention is a very powerful thing). There's nothing stopping you, however, from calling it this or even Martha.

4. The self argument to a method is simply a reference to the object that the method is being invoked on. We can access attributes and methods of that object as if it 
were any other object. This is exactly what we do inside the reset method when we set the x and y attributes of the self object.

5. Construction and Initialization:
when I call x = SomeClass(), __init__ is not the first thing to get called. Actually, it's a method called __new__, which actually creates the instance, then passes any 
arguments at creation on to the initializer. At the other end of the object's lifespan, there's __del__.

	1. __new__(cls, [...)
	__new__ is the first method to get called in an object's instantiation. It takes the class, then any other arguments that it will pass along to __init__. 
	__new__ is used fairly rarely, but it does have its purposes, particularly when subclassing an immutable type like a tuple or a string. for more details - 
	https://www.python.org/download/releases/2.2/descrintro/#__new__
	
	2. __init__(self, [...)
	The initializer for the class. It gets passed whatever the primary constructor was called with (so, for example, if we called x = SomeClass(10, 'foo'), 
	__init__ would get passed 10 and 'foo' as arguments. in case after 'init' someone calls 'new' again then after 'new', 'init' will not be called again. 
	
	3. __del__(self)
	If __new__ and __init__ formed the constructor of the object, __del__ is the destructor. It doesn't implement behavior for the statement del x (so that code would not 
	translate to x.__del__()). Rather, it defines behavior for when an object is garbage collected. It can be quite useful for objects that might require extra cleanup 
	upon deletion, like sockets or file objects. Be careful, however, as there is no guarantee that __del__ will be executed if the object is still alive when the 
	interpreter exits, so __del__ can't serve as a replacement for good coding practices (like always closing a connection when you're done with it. In fact, __del__ 
	should almost never be used because of the precarious circumstances under which it is called; use it with caution!
	
	4. __call__(self):
	Computing the value of the mathematical function represented by class Y from the section Representing a function as a class, with y as the name of the instance, 
	is performed by writing y.value(t). If we could write just y(t), the y instance would look as an ordinary function. Such a syntax is indeed possible and offered 
	by the special method named __call__. Writing y(t) implies a call y.__call__(t) 

6. Technically, every class we create uses inheritance. All Python classes are subclasses of the special class named object. This class provides very little in terms of 
data and behaviors (those behaviors it does provide are all double-underscore methods intended for internal use only), but it does allow Python to treat all objects in 
the same way.

-------------------------------------------------

Faking files - python 
Sometimes we need code that provides a file-like interface but doesn't actually read from or write to any real files. Two such adapters already exist in the standard library,
StringIO and BytesIO. They behave in much the same way, except that one deals with text characters and the second deals with bytes data. Both classes are available in the 
io package. To emulate a file open for reading, we can supply a string or bytes object to the constructor. Calls to read or readline will then parse that string as if 
it was a file. To emulate a file opened for writing, we simply construct a StringIO or BytesIO object and call the write or writelines methods. When writing is complete, 
we can discover the final contents of the written "file" using the getvalue method. It's really very simple

# coding=utf-8
from io import StringIO, BytesIO
source_file = StringIO("an oft-repeated cliché")
dest_file = BytesIO()
char = source_file.read(1)
while char:
    dest_file.write(char.encode("ascii", "replace"))
    char = source_file.read(1)
print(dest_file.getvalue())

------------------------------------------------------
python pickle: Storing objects

Nowadays, we take the ability to write data to a file and retrieve it at an arbitrary 
later date for granted. As convenient as this is (imagine the state of computing if 
we couldn't store anything!), we may often find ourselves converting data we have 
stored in a nice object or design pattern in memory into some kind of clunky text or 
binary format for storage.
The Python pickle module, allows us to store objects directly in a special object 
storage format. It essentially converts an object (and all the objects it holds as 
attributes) into a format that can be stored in a file or file-like object or a string of 
bytes that we can do whatever we want with.
For basic work, the pickle module has an extremely simple interface. It is comprised 
of four basic functions for storing and loading data; two for manipulating file-like 
objects, and two for manipulating bytes objects (the latter are just shortcuts to the 
file-like interface so we don't have to create a BytesIO file-like object ourselves).

The dump method accepts an object to be written and a file-like object to write the 
serialized bytes to. This object must have a write method (or it wouldn't be file-like), 
and that method must know how to handle a bytes argument (so a file opened for 
text output wouldn't work).
The load method does exactly the opposite; it reads a serialized object from a file-like 
object. This object must have the proper file-like read and readline arguments, each 
of which must, of course, return bytes. The pickle module will load the object from 
these bytes and the load method will return the fully reconstructed object. Here's an 
example that stores and then loads some data in a list object:
import pickle
some_data = ["a list", "containing", 5,
        "values including another list",
        ["inner", "list"]]
with open("pickled_list", 'wb') as file:
    pickle.dump(some_data, file)
with open("pickled_list", 'rb') as file:
    loaded_data = pickle.load(file)
print(loaded_data)
assert loaded_data == some_data


------------------------------------------
Given a string, the task is to check whether a string is valid json object or not
import json 
  
ini_string = "{'akshat' : 1, 'nikhil' : 2}"
  
# printing initial ini_string 
print ("initial string", ini_string) 
  
# checking for string 
try: 
    json_object = json.loads(ini_string) 
    print ("Is valid json? true") 
except ValueError as e: 
    print ("Is valid json? false") 

------------------------------------------------------------------------------------

Python Decorators
A decorator takes in a function, adds some functionality and returns it. In this article, you will learn how you can create a decorator and why you should use it.

Q.find time taken by a fuction using decorators.

https://www.programiz.com/python-programming/decorator

Note - We must be comfortable with the fact that, everything in Python (Yes! Even classes), are objects. Names that we define are simply identifiers bound to these objects.
Functions are no exceptions, they are objects too (with attributes). Various different names can be bound to the same function object.

def make_pretty(func):
    def inner():
        print("I got decorated")
        func()
    return inner

def ordinary():
    print("I am ordinary")

pretty = make_pretty(ordinary)
print(pretty())

Note - make_pretty is decorator. function ordinary() got decorated.

This is a common construct and for this reason, Python has a syntax to simplify this.

We can use the @ symbol along with the name of the decorator function and place it above the definition of the function to be decorated. For example,

@make_pretty
def ordinary():
    print("I am ordinary")
	
- The common patterns for decorators are:
Argument checking
Caching
Proxy
Context provider

Making a class that act as decorater:
To decorate a function, we need to return an object that can be used as a function. The classic implementation of the decorator pattern uses the fact that the way 
Pythonimplements regular procedural functions these functions can be seen as classes with some kind of execution method. In Python, everything is an object; functions are 
objects with a special __call__() method. If our decorator returns an object with a __call__() method, the result can be used as a function.

class ProfilingDecorator(object):
	def __init__(self, f):
		print("Profiling decorator initiated")
		self.f = f
	def __call__(self, *args):
		start_time = time.time()
		result = self.f(*args)
		end_time = time.time()
		print("[Time elapsed for n = {}] {}".format(n, end_time -
		start_time))
		return result
		
@ProfilingDecorator
def func(a):
	print a
	
In the class definition, we see that the decorated function is saved as an attribute of the object during initialization. Then, in the call function, the actual running 
of the function being decorated is wrapped in time requests. Just before returning, the profile value is printed to the console. When the compiler comes across the 
_@ProfilingDecorator_, it initiates an object and passes in the function being wrapped as an argument to the constructor. The returned object has the __call__() function as 
a method, and as such duck typing will allow this object to be used as a function. Also, note how we used *args in the __call__() method’s parameters to pass in arguments. 
*args allows us to handle multiple arguments coming in. This is called packing, as all the parameters coming in are packed into the args variable. Then, when we call the 
stored function in the f attribute of the decorating object, we once again use *args. This is called unpacking, and it turns all the elements of the collection in args into 
individual arguments that are passed on to the function in question.
-------------------------------------------------------
How for loop actually works in python?
So internally, the for loop creates an iterator object, iter_obj by calling iter() on the iterable.
Inside the loop, it calls next() to get the next element and executes the body of the for loop with this value. After all the items exhaust, StopIteration is raised which is 
internally caught and the loop ends. Note that any other kind of exception will pass through.
enumerate - This gives index and value both.
-------------------------------------------------------
Comprehensions in Python:
Note: A list comprehension is better method. It uses wired features that automate parts of the previous syntax:
list Comprehensions:
output_list = [var for var in input_list if (var condition)]
[x*x for x in range(1,10)]  ----- generator expressions or genexp

	Q. Count number of charecters in j, that are present in s as well.

	j = "aA"
	s = "aAAbbbb"

	def fun(s,j):
		return sum(1 for x in s if x in set(j))

	print fun (s,j)
	
	Q. a=[3,1,2,4]
	#O/P - [first even num then all odd number.]
	def func(a):
		return [num for num in a if num%2==0]+[num for num in a if num%2!=0]

	print func(a)
	
	Q.flipAndInvertImage
	I/P = [[1,1,0,0],[1,0,0,1],[0,1,1,1],[1,0,1,0]]
	O/P = [[1, 1, 0, 0], [0, 1, 1, 0], [0, 0, 0, 1], [1, 0, 1, 0]]
	a=[[1,1,0,0],[1,0,0,1],[0,1,1,1],[1,0,1,0]]

	def flipAndInvertImage(a):
		"""
		:type A: List[List[int]]
		:rtype: List[List[int]]
		"""
		res = []
		for row in a:
			res.append([1 - x for x in reversed(row)])
		return res

	print flipAndInvertImage(a)

Dictionary Comprehensions:
output_dict = {key:value for (key, value) in iterable if (key, value satisfy this condition)}
EX-1: {key:key*key for key in range(1,6) if key%2==0}
Ex-2:
state = ['Gujarat', 'Maharashtra', 'Rajasthan'] 
capital = ['Gandhinagar', 'Mumbai', 'Jaipur'] 
  
dict_using_comp = {key:value for (key, value) in zip(state, capital)} 

python map:
map(fun, iter)

filter(fun, list)
fun can be a lambda or a function
lambda arguments: expression
https://www.bogotobogo.com/python/python_functions_lambda.php
>>> (lambda x,y : x+y)(2,3)
5
>>> x = lambda x,y : x+y
>>> x(2,3)
5

>>> (lambda x:
... (x % 2 and 'odd' or 'even'))(3)
'odd'

-----------------------------------------------------
advance collections in python:
name tuple
defaultdict - a default value will be assigned. 
ordereddict - insertion order will be preserved.
deque object
counters - in collections module.

------------------------------------------------------

Local Symbol Table – stores information related to the local scope of the program. We can get this details using locals() function.
Global Symbol Table – stores information related to global scope of the program. We can get this details using globals() function.

-----------------------------------------------------------
use of python sorted function:
teams = [
    ('royals', (18, 12)),
('royals1', (34, 12)),
('royals2', (24, 12)),
('royals3', (12, 12)),
('royals4', (56, 12)),
('royals5', (13, 12)),
]

sorted_teams = sorted(teams, key=lambda team:team[1][0], reverse=True)
print sorted_teams
here consider team as on team's stats.
-----------------------------------------------------------

Encapsulation
To start a car engine, you only need to turn a key or press a button. You don’t need to connect wires under the hood, rotate
the crankshaft and cylinders, and initiate the power cycle of the engine. These details are hidden under the hood of the
car. You have only a simple interface: a start switch, a steering wheel and some pedals. This illustrates how each object has
an interface—a public part of an object, open to interactions with other objects.

class Car:

    def __init__(self):
        self.__updateSoftware()

    def drive(self):
        print('driving')

    def __updateSoftware(self):
        print('updating software')

redcar = Car()
redcar.drive()
#redcar.__updateSoftware()  not accesible from object.

--------------------------------------------------------------
Private variables:
class Car:

    __maxspeed = 0
    __name = ""
    
    def __init__(self):
        self.__maxspeed = 200
        self.__name = "Supercar"
    
    def drive(self):
        print('driving. maxspeed ' + str(self.__maxspeed))

    def setMaxSpeed(self,speed):
        self.__maxspeed = speed

redcar = Car()
redcar.drive()
redcar.setMaxSpeed(320)
redcar.drive()
--------------------------------------------------------------
Composition:

Composition is a way of aggregating objects together by making some objects attributes of other objects. following example covering the concept in details.

class Student:
    def __init__(self, name, student_number):
        self.name = name
        self.student_number = student_number
        self.classes = []

    def enrol(self, course_running):
        self.classes.append(course_running)
        course_running.add_student(self)

class Department:
    def __init__(self, name, department_code):
        self.name = name
        self.department_code = department_code
        self.courses = {}

    def add_course(self, description, course_code, credits):
        self.courses[course_code] = Course(description, course_code, credits, self)
        return self.courses[course_code]

class Course:
    def __init__(self, description, course_code, credits, department):
        self.description = description
        self.course_code = course_code
        self.credits = credits
        self.department = department
        self.department.add_course(self)

        self.runnings = []

    def add_running(self, year):
        self.runnings.append(CourseRunning(self, year))
        return self.runnings[-1]

class CourseRunning:
    def __init__(self, course, year):
        self.course = course
        self.year = year
        self.students = []

    def add_student(self, student):
        self.students.append(student)

maths_dept = Department("Mathematics and Applied Mathematics", "MAM")
mam1000w = maths_dept.add_course("Mathematics 1000", "MAM1000W", 1)
mam1000w_2013 = mam1000w.add_running(2013)
bob = Student("Bob", "Smith")
bob.enrol(mam1000w_2013)
------------------------------------------------
Working with the Python Super Function

	Python 2.2 saw the introduction of a built-in function called “super,” which returns a proxy object to delegate method calls to a class – which can be either parent 
	or sibling in nature.

	In other words, the super function can be used to gain access to inherited methods – from a parent or sibling class – that has been overwritten in a class object.

How Is the Super Function Used?

	The super function is somewhat versatile, and can be used in a couple of ways.

	Use Case 1: Super can be called upon in a single inheritance, in order to refer to the parent class or multiple classes without explicitly naming them. It’s somewhat 
	of a shortcut, but more importantly, it helps keep your code maintainable for the foreseeable future.

	Use Case 2: Super can be called upon in a dynamic execution environment for multiple or collaborative inheritance. This use is considered exclusive to Python, 
	because it’s not possible with languages that only support single inheritance or are statically compiled.

------------------------------------------------
Inheritance and super:
https://rhettinger.wordpress.com/2011/05/26/super-considered-super/
The __init__ method of the base class initialises all the instance variables that are common to all subclasses. In each subclass we override the __init__ method so that 
we can use it to initialise that class’s attributes – but we want the parent class’s attributes to be initialised as well, so we need to call the parent’s __init__ method 
from ours. To find the right method, we use the super function – when we pass in the current class and object as parameters, The super() builtin returns a proxy object, 
a substitute object that has ability to call method of the base class via delegation. This is called indirection (ability to reference base object with super())

MRO - https://makina-corpus.com/blog/metier/2014/python-tutorial-understanding-python-mro-class-search-path
class Mammal(object):
  def __init__(self, mammalName):
    print(mammalName, 'is a warm-blooded animal.')
    
class Dog(Mammal):
  def __init__(self):
    print('Dog has four legs.')
    super().__init__('Dog')
    
d1 = Dog()  

Example 2: super() with Multiple Inheritance

    class Animal:
      def __init__(self, animalName):
        print(animalName, 'is an animal.')
		
    class Mammal(Animal):
      def __init__(self, mammalName):
        print(mammalName, 'is a warm-blooded animal.')
        super().__init__(mammalName)
        
    class NonWingedMammal(Mammal):
      def __init__(self, NonWingedMammalName):
        print(NonWingedMammalName, "can't fly.")
        super().__init__(NonWingedMammalName)
    class NonMarineMammal(Mammal):
      def __init__(self, NonMarineMammalName):
        print(NonMarineMammalName, "can't swim.")
        super().__init__(NonMarineMammalName)
    class Dog(NonMarineMammal, NonWingedMammal):
      def __init__(self):
        print('Dog has 4 legs.');
        super().__init__('Dog')
        
    d = Dog()
    print('')
    bat = NonMarineMammal('Bat') 
		
>>>>> When you run the program, the output will be:
Dog has 4 legs.
Dog can't swim.
Dog can't fly.
Dog is a warm-blooded animal.
Dog is an animal.

Bat can't swim.
Bat is a warm-blooded animal.
Bat is an animal.

MRO(Method Resolution Order) in python:

In the multiple inheritance scenario, any specified attribute is searched first in the current class. If not found, the search continues into parent classes in depth-first,
left-right fashion without searching same class twice.

So, in the above example of MultiDerived class the search order is [MultiDerived, Base1, Base2, object]. This order is also called linearization of MultiDerived class and 
the set of rules used to find this order is called Method Resolution Order (MRO).

MRO must prevent local precedence ordering and also provide monotonicity. It ensures that a class always appears before its parents and in case of multiple parents, 
the order is same as tuple of base classes.

MRO of a class can be viewed as the __mro__ attribute or mro() method. The former returns a tuple while latter returns a list.

class Base1:
    pass

class Base2:
    pass

class MultiDerived(Base1, Base2):
    pass
	
In above example MRO is as following
>>> Dog.__mro__
(<class 'Dog'>, 
<class 'NonMarineMammal'>, 
<class 'NonWingedMammal'>, 
<class 'Mammal'>, 
<class 'Animal'>, 
<class 'object'>)

Here is how MRO is calculated in Python:

    A method in the derived calls is always called before the method of the base class.
    In our example, Dog class is called before NonMarineMammal or NoneWingedMammal. These two classes are called before Mammal which is called before Animal, 
    and Animal class is called before object.
    If there are multiple parents like Dog(NonMarineMammal, NonWingedMammal), method of NonMarineMammal is invoked first because it appears first.

---------------------------------------------------------------
Class decorators:(static method)

@classmethod

A class method is a method that is bound to a class rather than its object. It doesn't require creation of a class instance, much like staticmethod.

The difference between a static method and a class method is:

    Static method knows nothing about the class and just deals with the parameters
    Class method works with the class since its parameter is always the class itself.

--------------------------------------------------------------
Writting unit test for a lambda function:

import unittest

addtwo = lambda x: x + 2

class LambdaTest(unittest.TestCase):
    def test_add_two(self):
        self.assertEqual(addtwo(2), 4)

    def test_add_two_point_two(self):
        self.assertEqual(addtwo(2.2), 4.2)

    def test_add_three(self):
        # Should fail
        self.assertEqual(addtwo(3), 6)

if __name__ == '__main__':
    unittest.main(verbosity=2)
-------------------------------------------------------------------
XPath in Selenium WebDriver
xpath and different XPath expression are used to find the complex or dynamic elements, whose attributes changes dynamically on refresh or any operations.

Syntax for XPath:  Xpath=//tagname[@attribute='value']

details - https://www.guru99.com/xpath-selenium.html#1

--------------------------------------------------------------------
Iterators and Generators:
i = iter('a')
i.next()
'a'


Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration ---- once all is done.

Generator functions:
A function or method which uses the yield statement is called a generator function. Such a function, when called, always returns an iterator object which can be used to 
execute the body of the function: calling the iterator’s iterator.__next__() method will cause the function to execute until it provides a value using the yield statement.
When the function executes a return statement or falls off the end, a StopIteration exception is raised and the iterator will have reached the end of the set of values to 
be returned.

-------------------------------------------------------------------------

# When To Use __repr__ vs __str__?
# Emulate what the std lib does:
>>> import datetime
>>> today = datetime.date.today()

# Result of __str__ should be readable:
>>> str(today)
'2017-02-02'

# Result of __repr__ should be unambiguous:
>>> repr(today)
'datetime.date(2017, 2, 2)'

# Python interpreter sessions use 
# __repr__ to inspect objects:
>>> today
datetime.date(2017, 2, 2)

--------------------------------------------------------------------------
Data Model:
https://docs.python.org/3/reference/index.html

magic function:
https://rszalski.github.io/magicmethods/#context

meta class
https://www.python-course.eu/python3_metaclasses.php

--------------------------------------------------------------------------

-----------------------------------------------------------------------
How import works in python?
First, you need to know that the import keyword is actually a wrapper around a function named __import__.

import itertools >>> same as >>> itertools = __import__("itertools")

------------------------------------------------------------------------
difference b/w 'is' and '==':

The ‘is’ operator compares the identity of two objects; the id() function returns an integer representing its identity. if two objects are same then id for both of these 
objects will be same. '==' checks if value of two objects is same.
---------------------------------------------------------------------------

Q. A for loop is faster then a list comprehension.
in python(in C as well) when a function call made a new frame get created and then call past which takes type. list comprehension works same as a function does. 
means data frame creation. a simple for loop works in one frame. so it will save some time on these lines.

------------------------------------------------------------------------
Q. abstract class: 
Link:- https://www.python-course.eu/python3_abstract_classes.php
Abstract classes are classes that contain one or more abstract methods. An abstract method is a method that is declared, but contains no implementation. 
Abstract classes may not be instantiated, and require subclasses to provide implementations for the abstract methods. Subclasses of an abstract class in Python are not 
required to implement abstract methods of the parent class.

from abc import ABC, abstractmethod
 
class AbstractClassExample(ABC):
 
    def __init__(self, value):
        self.value = value
        super().__init__()
    
    @abstractmethod
    def do_something(self):
        pass
		
class DoAdd42(AbstractClassExample):
    def do_something(self):
        return self.value + 42
    
class DoMul42(AbstractClassExample):
   
    def do_something(self):
        return self.value * 42
    
x = DoAdd42(10)
y = DoMul42(10)
print(x.do_something())
print(y.do_something())

if do_something is not defined in sub class then following error will be raised.
TypeError: Can't instantiate abstract class DoAdd42 with abstract methods do_something
---------------------------------------------
python polimorphism:

Polymorphism means same function name (but different signatures) being uses for different types. For example

# Python program to demonstrate in-built poly-
# morphic functions
  
# len() being used for a string
print(len("geeks"))
  
# len() being used for a list
print(len([10, 20, 30]))

Polymorphism with class methods:
In literal sense, Polymorphism means the ability to take various forms. In Python, Polymorphism allows us to define methods in the child class with the same name as 
defined in their parent class.

As we know, a child class inherits all the methods from the parent class. However, you will encounter situations where the method inherited from the parent class doesn’t 
quite fit into the child class. In such cases, you will have to re-implement method in the child class. This process is known as Method Overriding.

If you have overridden a method in the child class, then the version of the method will be called based upon the type of the object used to call it. If a child class 
object is used to call an overridden method then the child class version of the method is called. On the other hand, if parent class object is used to call an overridden 
method, then the parent class version of the method is called.
----------------------------------------------

'__main__' is the name of the scope in which top-level code executes. A module’s __name__ is set equal to '__main__' when read from standard input, a script, or from an 
interactive prompt. A module can discover whether or not it is running in the main scope by checking its own __name__, which allows a common idiom for conditionally 
executing code in a module when it is run as a script or with python -m but not when it is imported:

-----------------------------------------------
Gherkin Syntax: BDD - behaviour development
Feature: Title of the Scenario
Given [Preconditions or Initial Context]
When [Event or Trigger]
Then [Expected output]

Gherkin Example:
Feature:  Login functionality of social networking site Facebook. 
Given:  I am a facebook user. 
When: I enter username as username. 
And I enter the password as the password 
Then I should be redirected to the home page of facebook 

Example 2:
Feature: User Authentication Background:
Given the user is already registered to the website Scenario:
Given the user is on the login page
When the user inputs the correct email address
And the user inputs the correct password
And the user clicks the Login button
Then the user should be authenticated
And the user should be redirected to their dashboard
And the user should be presented with a success message 

-----------------------------------------------------------
understanding of behave python framework.
What is BDD?

Behavioral Driven Development (BDD) is a software development approach that has evolved from TDD (Test Driven Development). It differs by being written in a shared 
language, which improves communication between tech and non-tech teams and stakeholders.In both development approaches, tests are written ahead of the code, but in BDD, 
tests are more user-focused and based on the system’s behavior.

https://blog.testlodge.com/what-is-bdd/

------------------------------------------------------------
Test Driven Development (TDD):
https://www.guru99.com/test-driven-development.html

------------------------------------------------------------

Behavior-Driven Development(BDD):
https://www.guru99.com/bdd-testing-rest-api-behave.html

-------------------------------------------------------------
pip show <module name> --- to see module is installed or not.
pip install abc==2.0.0

-------------------------------------------------------------
Python-tesseract is an optical character recognition (OCR) tool for python. That is, it will recognize and “read” the text embedded in images. Python-tesseract is a 
wrapper for Google’s Tesseract-OCR Engine. It is also useful as a stand-alone invocation script to tesseract, as it can read all image types supported by the Pillow and 
Leptonica imaging libraries, including jpeg, png, gif, bmp, tiff, and others. Additionally, if used as a script, Python-tesseract will print the recognized text instead 
of writing it to a file.
